{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 4., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.tensor([1.], requires_grad=True)\n",
    "y = torch.zeros((10))\n",
    "gt = torch.zeros((10))\n",
    "\n",
    "y[0] = a\n",
    "y[1] = y[0] * 2\n",
    "y.retain_grad()\n",
    "# retain : 유지하다.\n",
    "\n",
    "loss = torch.sum((y-gt) ** 2)\n",
    "loss.backward()\n",
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.tensor([1.], requires_grad=True)\n",
    "y = torch.zeros((10))\n",
    "gt = torch.zeros((10))\n",
    "\n",
    "y[0] = a\n",
    "y.retain_grad()\n",
    "y[1] = y[0] * 2\n",
    "\n",
    "loss = torch.sum((y-gt) ** 2)\n",
    "loss.backward()\n",
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retain_grad \n",
    "\n",
    "# convert any non-leaf tensor into a leaf tensor,\n",
    "# pytorch computes gradients to leaf tensors only\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grad is basically the value contained \n",
    "# in the grad attribute of the tensor after backward is called\n",
    "\n",
    "# retain_grad 를 통해 gradient 가 사라지는 것을 방지할수있따.\n",
    "# 계산그래프에서 leaf node가 아닌 tensor의 gradient는 계산 후 날라가는데,\n",
    "# retain_grad를 통해 날라가지 않고 붙잡을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ● leaf tensor ,non-leaf tensor\n",
    "# 공식doc : https://pytorch.org/docs/stable/generated/torch.Tensor.is_leaf.html\n",
    "\n",
    "\n",
    "# ● purpose of the leaf Tensor\n",
    "# 공식 Discussion  : https://discuss.pytorch.org/t/what-is-the-purpose-of-is-leaf/87000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requires_grad = False   => leaf Tensor\n",
    "# requires_grad = True    => will be leaf Tensor if they were created by user\n",
    "# requires_grad => contagious\n",
    "\n",
    "# Not the result of an operation and so grad_fn is None\n",
    "\n",
    "# Only leaf Tensors will have their grad populated during a call to backward().\n",
    "# To get grad populated for non-leaf Tensors, you can use retain_grad().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The grad fn for a is None\n",
      "The grad fn for d is <AddBackward0 object at 0x000001C548E41F10>\n"
     ]
    }
   ],
   "source": [
    "# grad_fn\n",
    "# refers to the mathematical operator that create the variable.\n",
    "\n",
    "# if requires_grad is set to False, grad_fn would be None.\n",
    "# if tensor is a leaf node, then the grad_fn is also None\n",
    "import torch \n",
    "\n",
    "a = torch.randn((3,3), requires_grad = True)\n",
    "\n",
    "w1 = torch.randn((3,3), requires_grad = True)\n",
    "w2 = torch.randn((3,3), requires_grad = True)\n",
    "w3 = torch.randn((3,3), requires_grad = True)\n",
    "w4 = torch.randn((3,3), requires_grad = True)\n",
    "\n",
    "b = w1*a \n",
    "c = w2*a\n",
    "\n",
    "d = w3*b + w4*c \n",
    "\n",
    "L = 10 - d\n",
    "\n",
    "print(\"The grad fn for a is\", a.grad_fn)\n",
    "print(\"The grad fn for d is\", d.grad_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
